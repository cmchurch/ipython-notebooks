{
 "metadata": {
  "name": "NLTK Workshop"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#imports\n",
      "import nltk #import the natural language toolkit library\n",
      "from nltk.stem.snowball import FrenchStemmer #import the French stemming library\n",
      "from nltk.corpus import stopwords #import stopwords from nltk corpus\n",
      "import re #import the regular expressions library; will be used to strip punctuation\n",
      "from collections import Counter #allows for counting the number of occurences in a list\n",
      "\n",
      "#reading in the raw text from the file\n",
      "path=\"D:\\\\PhD Research - UC Berkeley\\\\Research\\\\Pelee XML\\\\all-text.txt\" #set a file path of the text to read in\n",
      "f = open(path,\"r\") #open the file located at \"path\" as a file object (f) that is readonly\n",
      "raw = f.read().decode('utf8') # read raw text into a variable (raw) after decoding it from utf8\n",
      "f.close() #close the file now that it isn;t being used any longer\n",
      "\n",
      "#turn the raw text into an nltk text object\n",
      "no_commas = re.sub(r'[.|,|\\']',' ', raw) #filter out all the commas, periods, and appostrophes using regex\n",
      "tokens = nltk.word_tokenize(no_commas) #generate a list of tokens from the raw text\n",
      "text=nltk.Text(tokens) #create a nltk text from those tokens\n",
      "words=[w.lower() for w in text] #normalize the words in the text, making them all lowercase\n",
      "vocab = sorted(set(words)) #create a vocabulary of the words within the text\n",
      "\n",
      "#get French stopwords from the nltk kit\n",
      "nltk_frenchstopwords = stopwords.words('french') #create a list of all French stopwords\n",
      "nltk_frenchstopwords_unicode = [word.decode('utf8') for word in nltk_frenchstopwords] #make to decode the French stopwords as unicode objects rather than ascii\n",
      "\n",
      "#French Stopwords from Jean V\u00c9RONIS, Professeur de linguistique et d'informatique, University of Aix-en-Provence \n",
      "# http://sites.univ-provence.fr/~veronis/  http://sites.univ-provence.fr/veronis/data/antidico.txt\n",
      "#get veronis stopwords from list rather than from file\n",
      "#veronis_stopwords = [\"Ap.\", \"Apr.\", \"GHz\", \"MHz\", \"USD\", \"a\", \"afin\", \"ah\", \"ai\", \"aie\", \"aient\", \"aies\", \"ait\", \"alors\", \"apr\u00e8s\", \"as\", \"attendu\", \"au\", \"au-del\u00e0\", \"au-devant\", \"aucun\", \"aucune\", \"audit\", \"aupr\u00e8s\", \"auquel\", \"aura\", \"aurai\", \"auraient\", \"aurais\", \"aurait\", \"auras\", \"aurez\", \"auriez\", \"aurions\", \"aurons\", \"auront\", \"aussi\", \"autour\", \"autre\", \"autres\", \"autrui\", \"aux\", \"auxdites\", \"auxdits\", \"auxquelles\", \"auxquels\", \"avaient\", \"avais\", \"avait\", \"avant\", \"avec\", \"avez\", \"aviez\", \"avions\", \"avons\", \"ayant\", \"ayez\", \"ayons\", \"b\", \"bah\", \"banco\", \"ben\", \"bien\", \"b\u00e9\", \"c\", \"c'\", \"c'est\", \"c'\u00e9tait\", \"car\", \"ce\", \"ceci\", \"cela\", \"celle\", \"celle-ci\", \"celle-l\u00e0\", \"celles\", \"celles-ci\", \"celles-l\u00e0\", \"celui\", \"celui-ci\", \"celui-l\u00e0\", \"cel\u00e0\", \"cent\", \"cents\", \"cependant\", \"certain\", \"certaine\", \"certaines\", \"certains\", \"ces\", \"cet\", \"cette\", \"ceux\", \"ceux-ci\", \"ceux-l\u00e0\", \"cf.\", \"cg\", \"cgr\", \"chacun\", \"chacune\", \"chaque\", \"chez\", \"ci\", \"cinq\", \"cinquante\", \"cinquante-cinq\", \"cinquante-deux\", \"cinquante-et-un\", \"cinquante-huit\", \"cinquante-neuf\", \"cinquante-quatre\", \"cinquante-sept\", \"cinquante-six\", \"cinquante-trois\", \"cl\", \"cm\", \"cm\u00b2\", \"comme\", \"contre\", \"d\", \"d'\", \"d'apr\u00e8s\", \"d'un\", \"d'une\", \"dans\", \"de\", \"depuis\", \"derri\u00e8re\", \"des\", \"desdites\", \"desdits\", \"desquelles\", \"desquels\", \"deux\", \"devant\", \"devers\", \"dg\", \"diff\u00e9rentes\", \"diff\u00e9rents\", \"divers\", \"diverses\", \"dix\", \"dix-huit\", \"dix-neuf\", \"dix-sept\", \"dl\", \"dm\", \"donc\", \"dont\", \"douze\", \"du\", \"dudit\", \"duquel\", \"durant\", \"d\u00e8s\", \"d\u00e9j\u00e0\", \"e\", \"eh\", \"elle\", \"elles\", \"en\", \"en-dehors\", \"encore\", \"enfin\", \"entre\", \"envers\", \"es\", \"est\", \"et\", \"eu\", \"eue\", \"eues\", \"euh\", \"eurent\", \"eus\", \"eusse\", \"eussent\", \"eusses\", \"eussiez\", \"eussions\", \"eut\", \"eux\", \"e\u00fbmes\", \"e\u00fbt\", \"e\u00fbtes\", \"f\", \"fait\", \"fi\", \"flac\", \"fors\", \"furent\", \"fus\", \"fusse\", \"fussent\", \"fusses\", \"fussiez\", \"fussions\", \"fut\", \"f\u00fbmes\", \"f\u00fbt\", \"f\u00fbtes\", \"g\", \"gr\", \"h\", \"ha\", \"han\", \"hein\", \"hem\", \"heu\", \"hg\", \"hl\", \"hm\", \"hm\u00b3\", \"hol\u00e0\", \"hop\", \"hormis\", \"hors\", \"huit\", \"hum\", \"h\u00e9\", \"i\", \"ici\", \"il\", \"ils\", \"j\", \"j'\", \"j'ai\", \"j'avais\", \"j'\u00e9tais\", \"jamais\", \"je\", \"jusqu'\", \"jusqu'au\", \"jusqu'aux\", \"jusqu'\u00e0\", \"jusque\", \"k\", \"kg\", \"km\", \"km\u00b2\", \"l\", \"l'\", \"l'autre\", \"l'on\", \"l'un\", \"l'une\", \"la\", \"laquelle\", \"le\", \"lequel\", \"les\", \"lesquelles\", \"lesquels\", \"leur\", \"leurs\", \"lez\", \"lors\", \"lorsqu'\", \"lorsque\", \"lui\", \"l\u00e8s\", \"m\", \"m'\", \"ma\", \"maint\", \"mainte\", \"maintes\", \"maints\", \"mais\", \"malgr\u00e9\", \"me\", \"mes\", \"mg\", \"mgr\", \"mil\", \"mille\", \"milliards\", \"millions\", \"ml\", \"mm\", \"mm\u00b2\", \"moi\", \"moins\", \"mon\", \"moyennant\", \"mt\", \"m\u00b2\", \"m\u00b3\", \"m\u00eame\", \"m\u00eames\", \"n\", \"n'avait\", \"n'y\", \"ne\", \"neuf\", \"ni\", \"non\", \"nonante\", \"nonobstant\", \"nos\", \"notre\", \"nous\", \"nul\", \"nulle\", \"n\u00ba\", \"n\u00e9anmoins\", \"o\", \"octante\", \"oh\", \"on\", \"ont\", \"onze\", \"or\", \"ou\", \"outre\", \"o\u00f9\", \"p\", \"par\", \"par-del\u00e0\", \"parbleu\", \"parce\", \"parmi\", \"pas\", \"pass\u00e9\", \"pendant\", \"personne\", \"peu\", \"plus\", \"plus_d'un\", \"plus_d'une\", \"plusieurs\", \"pour\", \"pourquoi\", \"pourtant\", \"pourvu\", \"pr\u00e8s\", \"puisqu'\", \"puisque\", \"q\", \"qu\", \"qu'\", \"qu'elle\", \"qu'elles\", \"qu'il\", \"qu'ils\", \"qu'on\", \"quand\", \"quant\", \"quarante\", \"quarante-cinq\", \"quarante-deux\", \"quarante-et-un\", \"quarante-huit\", \"quarante-neuf\", \"quarante-quatre\", \"quarante-sept\", \"quarante-six\", \"quarante-trois\", \"quatorze\", \"quatre\", \"quatre-vingt\", \"quatre-vingt-cinq\", \"quatre-vingt-deux\", \"quatre-vingt-dix\", \"quatre-vingt-dix-huit\", \"quatre-vingt-dix-neuf\", \"quatre-vingt-dix-sept\", \"quatre-vingt-douze\", \"quatre-vingt-huit\", \"quatre-vingt-neuf\", \"quatre-vingt-onze\", \"quatre-vingt-quatorze\", \"quatre-vingt-quatre\", \"quatre-vingt-quinze\", \"quatre-vingt-seize\", \"quatre-vingt-sept\", \"quatre-vingt-six\", \"quatre-vingt-treize\", \"quatre-vingt-trois\", \"quatre-vingt-un\", \"quatre-vingt-une\", \"quatre-vingts\", \"que\", \"quel\", \"quelle\", \"quelles\", \"quelqu'\", \"quelqu'un\", \"quelqu'une\", \"quelque\", \"quelques\", \"quelques-unes\", \"quelques-uns\", \"quels\", \"qui\", \"quiconque\", \"quinze\", \"quoi\", \"quoiqu'\", \"quoique\", \"r\", \"revoici\", \"revoil\u00e0\", \"rien\", \"s\", \"s'\", \"sa\", \"sans\", \"sauf\", \"se\", \"seize\", \"selon\", \"sept\", \"septante\", \"sera\", \"serai\", \"seraient\", \"serais\", \"serait\", \"seras\", \"serez\", \"seriez\", \"serions\", \"serons\", \"seront\", \"ses\", \"si\", \"sinon\", \"six\", \"soi\", \"soient\", \"sois\", \"soit\", \"soixante\", \"soixante-cinq\", \"soixante-deux\", \"soixante-dix\", \"soixante-dix-huit\", \"soixante-dix-neuf\", \"soixante-dix-sept\", \"soixante-douze\", \"soixante-et-onze\", \"soixante-et-un\", \"soixante-et-une\", \"soixante-huit\", \"soixante-neuf\", \"soixante-quatorze\", \"soixante-quatre\", \"soixante-quinze\", \"soixante-seize\", \"soixante-sept\", \"soixante-six\", \"soixante-treize\", \"soixante-trois\", \"sommes\", \"son\", \"sont\", \"sous\", \"soyez\", \"soyons\", \"suis\", \"suite\", \"sur\", \"sus\", \"t\", \"t'\", \"ta\", \"tacatac\", \"tandis\", \"te\", \"tel\", \"telle\", \"telles\", \"tels\", \"tes\", \"toi\", \"ton\", \"toujours\", \"tous\", \"tout\", \"toute\", \"toutefois\", \"toutes\", \"treize\", \"trente\", \"trente-cinq\", \"trente-deux\", \"trente-et-un\", \"trente-huit\", \"trente-neuf\", \"trente-quatre\", \"trente-sept\", \"trente-six\", \"trente-trois\", \"trois\", \"tr\u00e8s\", \"tu\", \"u\", \"un\", \"une\", \"unes\", \"uns\", \"v\", \"vers\", \"via\", \"vingt\", \"vingt-cinq\", \"vingt-deux\", \"vingt-huit\", \"vingt-neuf\", \"vingt-quatre\", \"vingt-sept\", \"vingt-six\", \"vingt-trois\", \"vis-\u00e0-vis\", \"voici\", \"voil\u00e0\", \"vos\", \"votre\", \"vous\", \"w\", \"x\", \"y\", \"z\", \"z\u00e9ro\", \"\u00e0\", \"\u00e7'\", \"\u00e7a\", \"\u00e8s\", \"\u00e9taient\", \"\u00e9tais\", \"\u00e9tait\", \"\u00e9tant\", \"\u00e9tiez\", \"\u00e9tions\", \"\u00e9t\u00e9\", \"\u00e9t\u00e9e\", \"\u00e9t\u00e9es\", \"\u00e9t\u00e9s\", \"\u00eates\", \"\u00eatre\", \"\u00f4\"]\n",
      "f = open(\"D:\\\\PhD Research - UC Berkeley\\\\Research\\\\Pelee XML\\\\veronis-stopwords.txt\")\n",
      "veronis_stopwords_raw = f.read().decode('utf8')\n",
      "f.close();\n",
      "veronis_stopwords_unicode = veronis_stopwords_raw.split()\n",
      "\n",
      "#set which stopword list to use (nltk_frenchstopwords_unicode) or (veronis_stopwords_unicode)\n",
      "frenchstopwords_unicode = veronis_stopwords_unicode\n",
      "\n",
      "#filtering stopwords\n",
      "filtered_words = [] #declare an empty list to hold our filtered words\n",
      "for word in words: #iterate over all words from the text\n",
      "    if word not in frenchstopwords_unicode and word.isalpha() and len(word) > 1: #only add words that are not in the French stopwords list, are alphabetic, and are more than 1 character\n",
      "        filtered_words.append(word) #add word to filter_words list if it meets the above conditions\n",
      "filtered_words.sort() #sort filtered_words list\n",
      "\n",
      "#stemming words\n",
      "stemmed_words = [] #declare an empty list to hold our stemmed words\n",
      "stemmer = FrenchStemmer() #create a stemmer object in the FrenchStemmer class\n",
      "for word in filtered_words:\n",
      "    stemmed_word=stemmer.stem(word) #stem the word\n",
      "    stemmed_words.append(stemmed_word) #add it to our stemmed word list\n",
      "stemmed_words.sort() #sort the stemmed_words\n",
      "\n",
      "#counting and printing the stemmed words\n",
      "stemmed_words_count = Counter(stemmed_words) #count each occurence of the stemmed word in the list, and then create a dictionary of the returned result\n",
      "for key, value in sorted(stemmed_words_count.iteritems(), key=lambda (k,v): (v,k), reverse=True): #print the stemmed_words_count dictionary ordered in reverse order by the count\n",
      "    print \"%s: %s\" % (key, value)\n",
      "    \n",
      "#print text.concordance(\"catastrophe\",lines=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#USING STANFORD'S FRENCH POS TAGGER, v.3.2\n",
      "#http://nlp.stanford.edu/software/tagger.shtml\n",
      "#note: to get NLTK to find java with the tagger, I had to comment out lines 59 and 85 [config_java(options=self.java_options, verbose=False)] in stanford.py [C:\\Anaconda\\Lib\\site-packages\\nltk\\tag\\stanford.py]\n",
      "#then I had to set the python path directly\n",
      "\n",
      "# TAGS USED\n",
      "# MORPHOSYNTACTIC\n",
      "# A (adjective)\n",
      "# Adv (adverb)\n",
      "# CC (coordinating conjunction)\n",
      "# Cl (weak clitic pronoun)\n",
      "# CS (subordinating conjunction)\n",
      "# D (determiner)\n",
      "# ET (foreign word)\n",
      "# I (interjection)\n",
      "# NC (common noun)\n",
      "# NP (proper noun)\n",
      "# P (preposition)\n",
      "# PREF (prefix)\n",
      "# PRO (strong pronoun)\n",
      "# V (verb)\n",
      "# PONCT (punctuation mark)\n",
      "\n",
      "import nltk #import the Natural Language Processing Kit\n",
      "from nltk.tag.stanford import POSTagger #Get the Part of Speech tagger from NLP at Stanford, python module that interacts with Java\n",
      "nltk.internals.config_java(\"C:/Program Files/Java/jdk1.7.0_21/bin/java.exe\", options='-mx1000m',verbose=False) #set the path to java (note: i had to edit stanford.py and comment conflicting settings on lines 59 and 85\n",
      "jar_path=\"D:\\\\PhD Research - UC Berkeley\\\\Research\\\\Pelee XML\\\\stanford-postagger-full-2013-06-20\\\\stanford-postagger.jar\" #the absolute path the the stanford-postagger java file\n",
      "model_path = \"D:\\\\PhD Research - UC Berkeley\\\\Research\\\\Pelee XML\\\\stanford-postagger-full-2013-06-20\\\\models\\\\french.tagger\" #the absolute path to the french tagger model file\n",
      "pos_tagger = POSTagger(model_path,jar_path,encoding='utf8') #create an object of class POSTagger that is encoded in UTF-8\n",
      "\n",
      "to_tag = nltk.word_tokenize(raw) #tokenize the raw UTF-8 text\n",
      "tags = pos_tagger.tag(to_tag) #run the tagging algorithm on the tokenized raw text\n",
      "\n",
      "#print all the tags with their part of speech; tag[0] is the word; tag[1] is the Part of Speech\n",
      "for tag in tags: print tag[1]+'\\t',tag[0] \n",
      "\n",
      "#print all the adjectives; tag[0] is the word; tag[1] is the Part of Speech  \n",
      "for tag in tags: \n",
      "    if tag[1]=='A': print tag[0],\n",
      "\n",
      "#look for a particular POS word prior to the search term, see what comes after the search term\n",
      "search_term=\"martinique\"\n",
      "for i,tag in enumerate(tags):\n",
      "    if tags[i-1][1]=='D' and tag[0].lower()==search_term:\n",
      "        print str(i)+'\\t'+tags[i-1][0]+\"\\t\" + tag[0] + \"\\t\" + tags[i+1][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "L'effroyable enti\u00e8re humaines attroce \u00e9treint pareil philosophique entier nouvelle horrible vingt humaine. d'une sinistre enchant\u00e9s choy\u00e9s d'\u00e9pouvante beau queles fran\u00e7aises \u00e9clatante fortun\u00e9es terrestres riches dix-neuvi\u00e8me magique malheureux \u00e9taient-ils belle chaude poignante telles p\u00e9nible Eh d'efiorts bonne monstrueux d'une brutale sanguinaire haute sismiques d'hommes n'y mince sera-t-elle enti\u00e8re violente vaste ch\u00ebtive sera-t-el\u00eee astre premier qu'elle possible pr\u00e9caire d'\u00e9tranges unis commune nouvelle \u00e9pouvantable s'est br\u00e8ve arriv\u00e9e d'hier tous terrible qu'elle permis.Le suivante 8 55 an\u00e9antie quelques Tous volcanique grande commer\u00e7ante vingt-deux administratif s'est qu'ils libre d'un croissant saillante. rap Fort vaste \u00e0100 s'adosse \u00e9l\u00e9gantes verte d'altitude. petit s'est qu'on derni\u00e8re 18 vieille commercial foraine nombreux grandes environnante d'importance 6 qu'un br\u00fblante s'est volcanique 8 d'activit\u00e9. nouvelle absent douloureuse 8 dernier m\u00eame haute qu'on commerciale \u00e9lectorale derniers d'habitants nouvelles d\u00e9sol\u00e9e l'honorable premiers ouragan d'une inou\u00efe petite d'un d'un violent d\u00e9terre toute ( d'eau incalculable\u00bb 7 terrible nouveau m\u00eame '' terrible ler fameux normal 12 26 m\u00eame m\u00eame nouveau 13-14 terribles compl\u00e8te \u00e9pouvantable s\u00e9culaires supr\u00eame 440 580 grands petits Toutes 1766 18 m\u00eame tous mouill\u00e9s l'ancre haute toutes riveraines. nouveaux derni\u00e8re 10 funeste sousle grand fran\u00e7ais 6 7 qu'ils 26 second 11 Fort l'hopital militaire 8 ler toutes petite toutes successives principal dernier nord-ouest actuelle. 5 sismiques atmosph\u00e9riques ouragans 18 entiers trente p\u00e9rirent. volcan Tout voisin petit brusque terrible g\u00e9n\u00e9rale agr\u00e9able douce honn\u00eate seul grande d'y importante volcanique ancienne derniers chr\u00e9tienne c\u00e9l\u00e8bre I formidables mille 26 27 terrible grande seuls pr\u00e9alable p\u00e9rirent. compl\u00e9mentaires. m\u00eame t\u00e9l\u00e9graphiques nouvelles dure grand ancien centrale atterrir. suivante \u00e9quivalente laconique nouvelle volcanique quel efticace infortun\u00e9e irr\u00e9parable ult\u00e9rieures seul politique fran\u00e7aises pr\u00e9sent urgents m\u00eame l\u00e0-bas toute 5 d'importants br\u00fblante 5 Blanche compl\u00e9mentaires fran\u00e7aise t\u00e9l\u00e9graphiques certaine br\u00fbl\u00e9e Pouyer-Quertier impossible s'est nouvelle plupart Pouyer-Quertier Tout personnel t\u00e9l\u00e9graphiques deux ( 40 ) ( 55 ) ) hollandaise ( 777 ) deux dernier vaines l'indique premi\u00e8re toutes 8 dernier fran\u00e7ais eviste L'\u00e9pouvantable volcanique florissante humains incandescentes redoutables fragile souterraines palpitante s'exhale easourds domaine.ils anciens merveilleux hautes r\u00e9guli\u00e8re arrondis marin gigantesques nocturne. vraie volcanique c\u00f4ne redoutables parfait pittoresque Admirable prodigieuse caract\u00e9ristique terribles \u00e9clate longue supr\u00eame proche tremble souterraines Tout profond oscille nouveau \u00e9pais formidable lourdes l'espace d'\u00e9pais tout qu'aux foudre \u00e9clate fort mugit br\u00fblants fort effroyable s'ouvre incandescent n'ont tous petit autres moindre d'\u00e9pais environnante d'une d'\u00e9paisseur seul grand centrale Blanc cubes. \u00e9pouvantable petit cubes n\u00e9erlandais humains dur longues attentifs d\u00e9cevant l'aspect volcan Tel furieux humains. fr\u00e9quentes violentes s\u00e9culaire dure terribles furieux tous \u00e9teints j'ai hautes beaux altiers nouvelle terrible brusque \u00e9loign\u00e9 toute g\u00e9n\u00e9rale. nouvelles officielles suivant g\u00e9n\u00e9ral 8 m\u00eame premier derni\u00e8re qu'une tous disponibles second toute nouvelles D'autre nouvelles aucun toute particuli\u00e8res g\u00e9n\u00e9ral derni\u00e8re quelque nombreux anglaise am\u00e9ricaine certain diff\u00e9rentes 3 s'est ruraux 3 6 br\u00fblante Blanche Toutes deux br\u00fblante volcaniques impossible Ils'aper\u00e7urent anglais imp\u00e9n\u00e9trables possible d'\u00eatres vivants anglais autre anglais br\u00fbl\u00e9es. l'ancre vite. soudaine certain Tous morts mourants autre anglais 5 abondante grande 8 tous d'un\u00e8 16,000 noirs cr\u00e9oles 4,000 derniers principal d'immenses sucri\u00e8re nombreux inflammable. Toutes sortant r\u00e9publicain radical isol\u00e9 toutes toute \u00e9ruptive volcaniques consid\u00e9rables nouvelles s'est volcanique t\u00e9l\u00e9gramme nombreuses toutes jeunes tristes d'un \u00e9pouvantables 11 exact pais m\u00eames. Immense grande plein petit d'un faubourg nouvelle exact tous inquiets. '' nouvelles autre nouvelle terrible m\u00eame 9 premier vicaire g\u00e9n\u00e9ral s'est terrible g\u00e9n\u00e9ral qu'on sauv\u00e9e. grande moindre terrible insignifiante. petite Blanche 1 moindre violente vague vague vieilles quels premier vaste compl\u00e8te demi 9 nouvelle l'horrible profonde suivante bordelaises malheureuse bref possible v\u00e9ritable commerciaux importants nombreux s'y Divers maritimes l'initiative nouvelles utiles. \u00e9pouvantables 23 nouvelle marseillaises originaires \u00e9norme coloniale longues nouvelles maritime coloniale coloniale 10 toutes coloniales toutes d'assistance -charg\u00e9 l'effroyable anglaise unanime fran\u00e7aises anglaises danger. fran\u00e7aise d'une florissante. l'indescriptible coloniales fran\u00e7aise profonde cordiale vives. possible poignant soudaine autres s'est premi\u00e8res rares autre n\u00e9cessaires lui-m\u00eame mauvais premier d'un urgentes. autre autre 80 toutes n\u00e9cessaires toutes utiles national tous g\u00e9n\u00e9ral enti\u00e8re nouvelle anciennes ch\u00e8res maritimes jusqu'\u00e0 derniers officiels suivant d'hier consid\u00e9rable toute dure d'heure. vivants impossible Nombreux cadavres Tout tous rapide Tout personnel tous moyens toutes nouveau g\u00e9n\u00e9ral tous pr\u00e9sent priv\u00e9s dernier 24 suivants italien italien italien norv\u00e9gien fran\u00e7ais ( fran\u00e7ais italien italien italien fran\u00e7ais haut sauv\u00e9s. anglaise sinistr\u00e9s volcanique. Colonial suivant violemmenten compl\u00e8te d'une constante\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}